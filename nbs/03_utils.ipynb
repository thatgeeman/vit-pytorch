{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT model\n",
    "\n",
    "> Putting together patch embeddings and transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "from fastcore.basics import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class LossAccumulator(Metric):\n",
    "    \"\"\"\n",
    "    A PyTorch metric for accumulating loss values over multiple mini-batches.\n",
    "\n",
    "    This class inherits from the `Metric` class provided by the `torchmetrics` package.\n",
    "    It takes a loss function during initialization and uses it to calculate the loss for each batch during the update step.\n",
    "    The final loss value is calculated by averaging the total loss over the total number of elements.\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_func=nn.CrossEntropyLoss()):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self.add_state(\"loss\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, acts, target): \n",
    "        assert acts.shape[0] == target.shape[0]\n",
    "        acts, target = acts.to(self.device), target.to(self.device)\n",
    "        self.loss += self.loss_func(acts, target)\n",
    "        self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.loss / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossaccum = LossAccumulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1240)\n",
      "tensor(0.1212)\n",
      "tensor(0.1225)\n",
      "tensor(0.1247)\n",
      "tensor(0.1132)\n",
      "tensor(0.1177)\n",
      "tensor(0.1301)\n",
      "tensor(0.1309)\n",
      "tensor(0.1192)\n",
      "tensor(0.1303)\n",
      "avg loss: 0.12338263019919396\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "\n",
    "for i in range(10):\n",
    "    acts = nn.Softmax(dim=-1)(torch.rand(5, 2))\n",
    "    target = 1 * (acts[:,1]>0.5)\n",
    "    loss = lossaccum(acts, target)\n",
    "    # print(acts.dtype, target.dtype, loss)\n",
    "    print(loss)\n",
    "    tmp.append(loss.item())\n",
    "\n",
    "print(f\"avg loss: {np.mean(tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1234)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossaccum.compute() # reset after end of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "vit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
