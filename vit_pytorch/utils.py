# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_utils.ipynb.

# %% auto 0
__all__ = ['LossAccumulator']

# %% ../nbs/03_utils.ipynb 3
import torch
from torch import nn
import torch.functional as F
from torchvision import datasets
import numpy as np

import yaml
from fastcore.basics import Path

# %% ../nbs/03_utils.ipynb 5
class LossAccumulator(Metric):
    """
    A PyTorch metric for accumulating loss values over multiple mini-batches.

    This class inherits from the `Metric` class provided by the `torchmetrics` package.
    It takes a loss function during initialization and uses it to calculate the loss for each batch during the update step.
    The final loss value is calculated by averaging the total loss over the total number of elements.
    """
    def __init__(self, loss_func=nn.CrossEntropyLoss()):
        super().__init__()
        self.loss_func = loss_func
        self.add_state("loss", default=torch.tensor(0.), dist_reduce_fx="sum")
        self.add_state("total", default=torch.tensor(0.), dist_reduce_fx="sum")

    def update(self, acts, target): 
        assert acts.shape[0] == target.shape[0]
        acts, target = acts.to(self.device), target.to(self.device)
        self.loss += self.loss_func(acts, target)
        self.total += target.numel()

    def compute(self):
        return self.loss / self.total
